{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b813153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from folder structure...\n",
      "Loading digit 0: 1000 images\n",
      "Loading digit 1: 1000 images\n",
      "Loading digit 2: 1000 images\n",
      "Loading digit 3: 1000 images\n",
      "Loading digit 4: 1000 images\n",
      "Loading digit 5: 1000 images\n",
      "Loading digit 6: 1000 images\n",
      "Loading digit 7: 1000 images\n",
      "Loading digit 8: 1000 images\n",
      "Loading digit 9: 1000 images\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Total samples: 10000\n",
      "Image shape: 28x28 (784 features)\n",
      "Classes: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Class distribution:\n",
      "  Digit 0: 1000 samples\n",
      "  Digit 1: 1000 samples\n",
      "  Digit 2: 1000 samples\n",
      "  Digit 3: 1000 samples\n",
      "  Digit 4: 1000 samples\n",
      "  Digit 5: 1000 samples\n",
      "  Digit 6: 1000 samples\n",
      "  Digit 7: 1000 samples\n",
      "  Digit 8: 1000 samples\n",
      "  Digit 9: 1000 samples\n",
      "Normalized: range [0.000, 1.000]\n",
      "\n",
      "Preprocessing data...\n",
      "Training set: 8000 samples\n",
      "Testing set: 2000 samples\n",
      "Feature shape: 784 features\n",
      "\n",
      "Preprocessed data saved to preprocessed_data.pkl\n",
      "\n",
      "============================================================\n",
      "Data preprocessing completed!\n",
      "============================================================\n",
      "\n",
      "You can now use this data to train your models.\n",
      "The preprocessed data has been saved to 'preprocessed_data.pkl'\n",
      "\n",
      "DATASET STATISTICS\n",
      "----------------------------------------\n",
      "Total Samples: 10000\n",
      "Training Samples: 8000\n",
      "Test Samples: 2000\n",
      "Features: 784\n",
      "Number of Classes: 10\n",
      "\n",
      "Training Set Distribution: [800 800 800 800 800 800 800 800 800 800]\n",
      "Test Set Distribution: [200 200 200 200 200 200 200 200 200 200]\n",
      "\n",
      "Pixel Value Mean: 0.4261\n",
      "Pixel Value Std: 0.1662\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, data_folder='10000'):\n",
    "        self.data_folder = data_folder\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        \n",
    "    def load_images_from_folder(self):\n",
    "\n",
    "        print(\"Loading images from folder structure...\")\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Loop through each digit folder (0-9)\n",
    "        for digit in range(10):\n",
    "            digit_folder = os.path.join(self.data_folder, str(digit))\n",
    "            \n",
    "            if not os.path.exists(digit_folder):\n",
    "                print(f\"Warning: Folder {digit_folder} not found!\")\n",
    "                continue\n",
    "            \n",
    "            # Get all image files in the digit folder\n",
    "            image_files = [f for f in os.listdir(digit_folder) \n",
    "                          if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "            \n",
    "            print(f\"Loading digit {digit}: {len(image_files)} images\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(digit_folder, img_file)\n",
    "                \n",
    "                try:\n",
    "                    # Load image and convert to grayscale\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    \n",
    "                    # Resize to 28x28 if necessary\n",
    "                    img = img.resize((28, 28))\n",
    "                    \n",
    "                    # Convert to numpy array and flatten\n",
    "                    img_array = np.array(img).flatten()\n",
    "                    \n",
    "                    images.append(img_array)\n",
    "                    labels.append(digit)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "        \n",
    "        self.X = np.array(images)\n",
    "        self.y = np.array(labels)\n",
    "        \n",
    "        print(f\"\\nDataset loaded successfully!\")\n",
    "        print(f\"Total samples: {len(self.X)}\")\n",
    "        print(f\"Image shape: 28x28 (784 features)\")\n",
    "        print(f\"Classes: {np.unique(self.y)}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        print(\"\\nClass distribution:\")\n",
    "        for digit in range(10):\n",
    "            count = np.sum(self.y == digit)\n",
    "            print(f\"  Digit {digit}: {count} samples\")\n",
    "        \n",
    "        return self.X, self.y\n",
    "    \n",
    "    \n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Comprehensive preprocessing for MNIST-like images\n",
    "        \"\"\"\n",
    "        # 1. Normalize to [0, 1]\n",
    "        X_normalized = self.X.astype('float32') / 255.0\n",
    "\n",
    "        # 2. Invert if needed (black on white â†’  white on black)\n",
    "        X_inverted = 1.0 - X_normalized\n",
    "\n",
    "\n",
    "\n",
    "        self.X = X_inverted\n",
    "        print(f\"Normalized: range [{np.min(self.X):.3f}, {np.max(self.X):.3f}]\")\n",
    "\n",
    "    def split(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Normalize pixel values and split into train/test sets\n",
    "        \"\"\"\n",
    "        print(\"\\nPreprocessing data...\")\n",
    "        \n",
    "\n",
    "        # Split into train and test sets (80-20 split)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state, \n",
    "            stratify=self.y\n",
    "        )\n",
    "\n",
    "\n",
    "        print(f\"Training set: {self.X_train.shape[0]} samples\")\n",
    "        print(f\"Testing set: {self.X_test.shape[0]} samples\")\n",
    "        print(f\"Feature shape: {self.X_train.shape[1]} features\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def save_preprocessed_data(self, output_file='preprocessed_data.pkl'):\n",
    "        \"\"\"\n",
    "        Save preprocessed data for reuse\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            'X_train': self.X_train,\n",
    "            'X_test': self.X_test,\n",
    "            'y_train': self.y_train,\n",
    "            'y_test': self.y_test\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        \n",
    "        print(f\"\\nPreprocessed data saved to {output_file}\")\n",
    "    \n",
    "    def load_preprocessed_data(self, input_file='preprocessed_data.pkl'):\n",
    "        \"\"\"\n",
    "        Load previously saved preprocessed data\n",
    "        \"\"\"\n",
    "        print(f\"Loading preprocessed data from {input_file}...\")\n",
    "        \n",
    "        with open(input_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.X_train = data['X_train']\n",
    "        self.X_test = data['X_test']\n",
    "        self.y_train = data['y_train']\n",
    "        self.y_test = data['y_test']\n",
    "        \n",
    "        print(\"Preprocessed data loaded successfully!\")\n",
    "        print(f\"Training set: {self.X_train.shape[0]} samples\")\n",
    "        print(f\"Testing set: {self.X_test.shape[0]} samples\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "\n",
    "def print_data_statistics(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Print dataset statistics\n",
    "    \"\"\"\n",
    "    print(\"\\nDATASET STATISTICS\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"Total Samples: {len(X_train) + len(X_test)}\")\n",
    "    print(f\"Training Samples: {len(X_train)}\")\n",
    "    print(f\"Test Samples: {len(X_test)}\")\n",
    "    print(f\"Features: {X_train.shape[1]}\")\n",
    "    print(f\"Number of Classes: {len(np.unique(y_train))}\")\n",
    "    print(f\"\\nTraining Set Distribution: {np.bincount(y_train)}\")\n",
    "    print(f\"Test Set Distribution: {np.bincount(y_test)}\")\n",
    "    print(f\"\\nPixel Value Mean: {np.mean(X_train):.4f}\")\n",
    "    print(f\"Pixel Value Std: {np.std(X_train):.4f}\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load and preprocess data\n",
    "    \"\"\"\n",
    "    # Initialize data loader\n",
    "    loader = DataLoader(data_folder='10000')\n",
    "    \n",
    "    # Load images from folder structure\n",
    "    loader.X, loader.y = loader.load_images_from_folder()\n",
    "    \n",
    "    loader.normalize()\n",
    "    # Preprocess data (normalize and split)\n",
    "    X_train, X_test, y_train, y_test = loader.split(test_size=0.2)\n",
    "    \n",
    "    # Save preprocessed data for reuse\n",
    "    loader.save_preprocessed_data('preprocessed_data.pkl')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Data preprocessing completed!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nYou can now use this data to train your models.\")\n",
    "    print(\"The preprocessed data has been saved to 'preprocessed_data.pkl'\")\n",
    "    print_data_statistics(X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "            main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
